{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy Examples with Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.damtp.cam.ac.uk/pysr/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pysr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Simple search`\n",
    "\n",
    "拟合公式 $$ 2 \\cos (x_3) + x_0^2 - 2  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taizun\\miniconda3\\envs\\syh\\lib\\site-packages\\pysr\\sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Julia backend...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySRRegressor.equations_ = [\n",
      "\t   pick     score                                           equation  \\\n",
      "\t0        0.000000                                            x0 * x0   \n",
      "\t1        0.480453                             -1.8618065 + (x0 * x0)   \n",
      "\t2        0.001592             -1.8601245 + ((x0 - 0.039912477) * x0)   \n",
      "\t3        0.036267      -1.8618065 + (x0 * (x0 + (-0.10506168 * x3)))   \n",
      "\t4        0.269381  (x0 * x0) - (x3 * (-0.34305695 * (0.12588452 -...   \n",
      "\t5  >>>>  0.226663  ((x0 * x0) + -0.85416466) - (x3 * ((0.1668744 ...   \n",
      "\t6        0.007926  ((x0 * x0) + -0.85416466) - (x3 * (((0.1668744...   \n",
      "\t7        0.023294  (-0.8539921 + (x0 * x0)) - (x3 * ((((x3 * 0.02...   \n",
      "\t8        0.016230  (-0.8539921 + (x0 * x0)) - (x3 * ((((x3 * 0.02...   \n",
      "\t\n",
      "\t       loss  complexity  \n",
      "\t0  5.613928           3  \n",
      "\t1  2.147588           5  \n",
      "\t2  2.140760           7  \n",
      "\t3  1.990981           9  \n",
      "\t4  1.161678          11  \n",
      "\t5  0.738260          13  \n",
      "\t6  0.726649          15  \n",
      "\t7  0.693572          17  \n",
      "\t8  0.671420          19  \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "X = 2 * np.random.randn(100, 5)\n",
    "y = 2 * np.cos(X[:, 3]) + X[:, 0] ** 2 - 2\n",
    "model = PySRRegressor(binary_operators=[\"+\", \"-\", \"*\", \"/\"])\n",
    "model.fit(X, y)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Custom operator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taizun\\miniconda3\\envs\\syh\\lib\\site-packages\\pysr\\sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "[ Info: Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySRRegressor.equations_ = [\n",
      "\t   pick      score   equation          loss  complexity\n",
      "\t0         0.000000  1.5116882  5.312147e+01           1\n",
      "\t1  >>>>  34.881849    inv(x0)  3.769429e-14           2\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "X = 2 * np.random.randn(100, 5)\n",
    "y = 1 / X[:, 0]\n",
    "model = PySRRegressor(\n",
    "    binary_operators=[\"+\", \"*\"],\n",
    "    unary_operators=[\"inv(x) = 1/x\"],\n",
    "    extra_sympy_mappings={\"inv\": lambda x: 1/x},\n",
    ")\n",
    "model.fit(X, y)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Multiple outputs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taizun\\miniconda3\\envs\\syh\\lib\\site-packages\\pysr\\sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "[ Info: Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expressions evaluated per second: 3.950e+05\n",
      "Head worker occupation: 13.3%\n",
      "Progress: 847 / 1800 total iterations (47.056%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 3.130e+05\n",
      "Head worker occupation: 23.5%\n",
      "Progress: 1305 / 1800 total iterations (72.500%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 2.150e+05\n",
      "Head worker occupation: 34.7%\n",
      "Progress: 1384 / 1800 total iterations (76.889%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 1.660e+05\n",
      "Head worker occupation: 42.7%. This is high, and will prevent efficient resource usage. Increase `ncycles_per_iteration` to reduce load on head worker.\n",
      "Progress: 1445 / 1800 total iterations (80.278%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 8.720e+04\n",
      "Head worker occupation: 46.3%. This is high, and will prevent efficient resource usage. Increase `ncycles_per_iteration` to reduce load on head worker.\n",
      "Progress: 1521 / 1800 total iterations (84.500%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 3.400e+04\n",
      "Head worker occupation: 49.5%. This is high, and will prevent efficient resource usage. Increase `ncycles_per_iteration` to reduce load on head worker.\n",
      "Progress: 1596 / 1800 total iterations (88.667%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 3.480e+04\n",
      "Head worker occupation: 52.4%. This is high, and will prevent efficient resource usage. Increase `ncycles_per_iteration` to reduce load on head worker.\n",
      "Progress: 1679 / 1800 total iterations (93.278%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 3.510e+04\n",
      "Head worker occupation: 53.3%. This is high, and will prevent efficient resource usage. Increase `ncycles_per_iteration` to reduce load on head worker.\n",
      "Progress: 1745 / 1800 total iterations (96.944%)\n",
      "====================================================================================================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.593e+03  1.594e+01  y₀ = x₃\n",
      "2           1.495e-13  1.594e+01  y₀ = inv(x₀)\n",
      "8           1.495e-13  4.937e-06  y₀ = ((1.2569 + x₄) * 2.9375e-09) + inv(x₀)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.238e+01  1.594e+01  y₁ = 0.33672\n",
      "2           5.106e-14  1.594e+01  y₁ = inv(x₁)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "2           1.156e-14  7.971e+00  y₂ = inv(x₂)\n",
      "8           1.155e-14  1.281e-04  y₂ = 0.010385 + (inv(x₂) + (-0.16866 * 0.061572))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PySRRegressor.equations_ = [\n",
       "[\n",
       "\t   pick      score                                    equation          loss  \\\n",
       "\t0         0.000000                                          x3  9.593046e+03   \n",
       "\t1  &gt;&gt;&gt;&gt;  38.700108                                     inv(x0)  1.495248e-13   \n",
       "\t2         0.000005  ((1.2568897 + x4) * 2.937454e-9) + inv(x0)  1.495204e-13   \n",
       "\t\n",
       "\t   complexity  \n",
       "\t0           1  \n",
       "\t1           2  \n",
       "\t2           8  \n",
       "], [\n",
       "\t   pick      score   equation          loss  complexity\n",
       "\t0         0.000000  0.3367189  1.238417e+01           1\n",
       "\t1  &gt;&gt;&gt;&gt;  33.122123    inv(x1)  5.106360e-14           2\n",
       "], [\n",
       "\t   pick     score                                           equation  \\\n",
       "\t0        0.000000                                            inv(x2)   \n",
       "\t1  &gt;&gt;&gt;&gt;  0.000128  0.010384511 + (inv(x2) + (-0.16865532 * 0.0615...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  1.155964e-14           2  \n",
       "\t1  1.155076e-14           8  \n",
       "]]</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PySRRegressor</label><div class=\"sk-toggleable__content\"><pre>PySRRegressor.equations_ = [\n",
       "[\n",
       "\t   pick      score                                    equation          loss  \\\n",
       "\t0         0.000000                                          x3  9.593046e+03   \n",
       "\t1  &gt;&gt;&gt;&gt;  38.700108                                     inv(x0)  1.495248e-13   \n",
       "\t2         0.000005  ((1.2568897 + x4) * 2.937454e-9) + inv(x0)  1.495204e-13   \n",
       "\t\n",
       "\t   complexity  \n",
       "\t0           1  \n",
       "\t1           2  \n",
       "\t2           8  \n",
       "], [\n",
       "\t   pick      score   equation          loss  complexity\n",
       "\t0         0.000000  0.3367189  1.238417e+01           1\n",
       "\t1  &gt;&gt;&gt;&gt;  33.122123    inv(x1)  5.106360e-14           2\n",
       "], [\n",
       "\t   pick     score                                           equation  \\\n",
       "\t0        0.000000                                            inv(x2)   \n",
       "\t1  &gt;&gt;&gt;&gt;  0.000128  0.010384511 + (inv(x2) + (-0.16865532 * 0.0615...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  1.155964e-14           2  \n",
       "\t1  1.155076e-14           8  \n",
       "]]</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PySRRegressor.equations_ = [\n",
       "[\n",
       "\t   pick      score                                    equation          loss  \\\n",
       "\t0         0.000000                                          x3  9.593046e+03   \n",
       "\t1  >>>>  38.700108                                     inv(x0)  1.495248e-13   \n",
       "\t2         0.000005  ((1.2568897 + x4) * 2.937454e-9) + inv(x0)  1.495204e-13   \n",
       "\t\n",
       "\t   complexity  \n",
       "\t0           1  \n",
       "\t1           2  \n",
       "\t2           8  \n",
       "], [\n",
       "\t   pick      score   equation          loss  complexity\n",
       "\t0         0.000000  0.3367189  1.238417e+01           1\n",
       "\t1  >>>>  33.122123    inv(x1)  5.106360e-14           2\n",
       "], [\n",
       "\t   pick     score                                           equation  \\\n",
       "\t0        0.000000                                            inv(x2)   \n",
       "\t1  >>>>  0.000128  0.010384511 + (inv(x2) + (-0.16865532 * 0.0615...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  1.155964e-14           2  \n",
       "\t1  1.155076e-14           8  \n",
       "]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 2 * np.random.randn(100, 5)\n",
    "y = 1 / X[:, [0, 1, 2]] # 可以看到这里有多个输入\n",
    "model = PySRRegressor(\n",
    "    binary_operators=[\"+\", \"*\"],\n",
    "    unary_operators=[\"inv(x) = 1/x\"],\n",
    "    extra_sympy_mappings={\"inv\": lambda x: 1/x},\n",
    ")\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Plotting an expression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\frac{1}{x_{0}}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.latex()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(y[:, 0], model.predict(X)[:, 0])\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Feature selection`\n",
    "\n",
    "PySR and evolution-based symbolic regression in general performs very poorly when the number of features is large. Even, say, 10 features might be too much for a typical equation search.\n",
    "\n",
    "If you are dealing with high-dimensional data with a particular type of structure, you might consider using deep learning to break the problem into smaller \"chunks\" which can then be solved by PySR, as explained in the paper https://arxiv.org/abs/2006.11287\n",
    "\n",
    "For tabular datasets, this is a bit trickier. Luckily, PySR has a built-in feature selection mechanism. Simply declare the parameter `select_k_features=5`, for selecting the most important 5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(300, 30)\n",
    "y = X[:, 3]**2 - X[:, 19]**2 + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PySRRegressor(\n",
    "    binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "    unary_operators=[\"exp\"],\n",
    "    select_k_features=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taizun\\miniconda3\\envs\\syh\\lib\\site-packages\\pysr\\sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features ['x3' 'x7' 'x10' 'x19' 'x26']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Started!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PySRRegressor.equations_ = [\n",
       "\t   pick      score                                           equation  \\\n",
       "\t0         0.000000                                      exp(0.574352)   \n",
       "\t1         0.639663                                            x3 * x3   \n",
       "\t2         0.093628                             0.57598937 + (x3 * x3)   \n",
       "\t3         0.004532               ((x3 / 1.0834885) * x3) - -0.6685054   \n",
       "\t4  &gt;&gt;&gt;&gt;  15.843462                   ((x3 * x3) - (x19 * x19)) - -1.5   \n",
       "\t5         0.017426  (((x3 * x3) - (x19 * x19)) + 0.7949385) + 0.70...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  3.684310e+00           2  \n",
       "\t1  1.943363e+00           3  \n",
       "\t2  1.611496e+00           5  \n",
       "\t3  1.596956e+00           7  \n",
       "\t4  2.765902e-14           9  \n",
       "\t5  2.671163e-14          11  \n",
       "]</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PySRRegressor</label><div class=\"sk-toggleable__content\"><pre>PySRRegressor.equations_ = [\n",
       "\t   pick      score                                           equation  \\\n",
       "\t0         0.000000                                      exp(0.574352)   \n",
       "\t1         0.639663                                            x3 * x3   \n",
       "\t2         0.093628                             0.57598937 + (x3 * x3)   \n",
       "\t3         0.004532               ((x3 / 1.0834885) * x3) - -0.6685054   \n",
       "\t4  &gt;&gt;&gt;&gt;  15.843462                   ((x3 * x3) - (x19 * x19)) - -1.5   \n",
       "\t5         0.017426  (((x3 * x3) - (x19 * x19)) + 0.7949385) + 0.70...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  3.684310e+00           2  \n",
       "\t1  1.943363e+00           3  \n",
       "\t2  1.611496e+00           5  \n",
       "\t3  1.596956e+00           7  \n",
       "\t4  2.765902e-14           9  \n",
       "\t5  2.671163e-14          11  \n",
       "]</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PySRRegressor.equations_ = [\n",
       "\t   pick      score                                           equation  \\\n",
       "\t0         0.000000                                      exp(0.574352)   \n",
       "\t1         0.639663                                            x3 * x3   \n",
       "\t2         0.093628                             0.57598937 + (x3 * x3)   \n",
       "\t3         0.004532               ((x3 / 1.0834885) * x3) - -0.6685054   \n",
       "\t4  >>>>  15.843462                   ((x3 * x3) - (x19 * x19)) - -1.5   \n",
       "\t5         0.017426  (((x3 * x3) - (x19 * x19)) + 0.7949385) + 0.70...   \n",
       "\t\n",
       "\t           loss  complexity  \n",
       "\t0  3.684310e+00           2  \n",
       "\t1  1.943363e+00           3  \n",
       "\t2  1.611496e+00           5  \n",
       "\t3  1.596956e+00           7  \n",
       "\t4  2.765902e-14           9  \n",
       "\t5  2.671163e-14          11  \n",
       "]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the Julia backend is launched, you can see the string:\n",
    "\n",
    "`Using features ['x3', 'x5', 'x7', 'x19', 'x21']`\n",
    "\n",
    "which indicates that the feature selection (powered by a gradient-boosting tree) has successfully selected the relevant two features.\n",
    "\n",
    "This fit should find the solution quickly, whereas with the huge number of features, it would have struggled.\n",
    "\n",
    "This simple preprocessing step is enough to simplify our tabular dataset, but again, for more structured datasets, you should try the deep learning approach mentioned above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
